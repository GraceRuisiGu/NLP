{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Ruisi_Gu -- Sub-Notebook One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report is to tackle a Kaggle Competition, \"Sentiment Analysis on Movie Reviews\". The aim of this competition is to classify the sentiment of sentences from the Rotten Tomatoes dataset. The evaluation standard is based on classification accuracy (the percent of labels that are predicted correctly) for every parsed phrase. The sentiment labels are: 0 - negative, 1 - somewhat negative, 2 - neutral, 3 - somewhat positive and 4 - positive, respectively. Therefore, the evaluation rules for my models would be the accuracy of confusion matrix.<br><br>\n",
    "To get a better result, I would like to roughly separate the report into three parts. The first one is **Cleaning  and Preprocessing Data** and the second one is **Fit in Models and comparison**.<br><br>\n",
    "Since the first two parts are using tensorflow and sklearn, the last one is using H2O library, I have to separate the notebook into two sub-notebooks. Here is the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One -- Cleaning and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      "PhraseId      156060 non-null int64\n",
      "SentenceId    156060 non-null int64\n",
      "Phrase        156060 non-null object\n",
      "Sentiment     156060 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "\n",
    "train_df = pandas.read_csv(\"data/train.tsv\", sep=\"\\t\")\n",
    "test_df = pandas.read_csv(\"data/test.tsv\", sep=\"\\t\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem the data using nltk PorterStemmer which changes the words like \"pythoner\", \"pythoning\" etc. to the \"python\". And lowered all phrases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "STEMMER = nltk.stem.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "def custom_tokenizer(document):\n",
    "    regexp = re.compile(r\"(?u)\\b\\w\\w+\\b\", flags=re.IGNORECASE)\n",
    "    words = regexp.findall(document)\n",
    "    return [STEMMER.stem(word.lower()) for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_df[\"Phrase\"].copy(), train_df[\"Sentiment\"].copy()\n",
    "ids, x_test = test_df[\"PhraseId\"].copy(), test_df[\"Phrase\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<156060x4873 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 912378 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=20, tokenizer=custom_tokenizer)\n",
    "x_train_vect = vectorizer.fit_transform(x_train)\n",
    "x_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation score: 0.613 (+/- 0.002)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "estimator = MultinomialNB()\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=.25, random_state=0)\n",
    "cv_scores = cross_val_score(estimator, x_train_vect, y_train, cv=cv)\n",
    "mean, std = cv_scores.mean(), cv_scores.std()\n",
    "\n",
    "print(f\"Mean cross-validation score: {mean:.3f} (+/- {std:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=20,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       " ...   vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "pipe = make_pipeline(vectorizer, estimator)\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate New Data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the predictions based the model we've created on both train and test dataset, create a new column to save the prediction. These two datasets are the one we will do further explore on. The names of new training and testing dataset are train_submission and submission06 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <td>156061</td>\n",
       "      <td>156062</td>\n",
       "      <td>156063</td>\n",
       "      <td>156064</td>\n",
       "      <td>156065</td>\n",
       "      <td>156066</td>\n",
       "      <td>156067</td>\n",
       "      <td>156068</td>\n",
       "      <td>156069</td>\n",
       "      <td>156070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SentimentM1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1       2       3       4       5       6       7  \\\n",
       "PhraseId     156061  156062  156063  156064  156065  156066  156067  156068   \n",
       "SentimentM1       3       3       2       3       3       3       3       3   \n",
       "\n",
       "                  8       9  \n",
       "PhraseId     156069  156070  \n",
       "SentimentM1       3       2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pipe.predict(x_test)\n",
    "\n",
    "submission = pandas.DataFrame(data={\n",
    "    \"PhraseId\": ids,\n",
    "    \"SentimentM1\": predictions\n",
    "})\n",
    "submission.to_csv(\"submission06.csv\", index=False)\n",
    "submission.head(n=10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = pipe.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_submission  = pandas.read_csv(\"data/train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_submission['SentimentM1'] = predictions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_submission.to_csv('train_submission.csv', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
